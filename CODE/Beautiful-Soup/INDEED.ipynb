{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page1 = 'https://www.indeed.com/jobs?q=software+developer&l=Tempe%2C+AZ&sc=0kf%3Aexplvl%28ENTRY_LEVEL%29%3B&vjk=56fce1f730a31d57'\n",
    "\n",
    "page2 = 'https://www.indeed.com/jobs?q=software+developer&l=Tempe%2C+AZ&radius=50&start=10&pp=gQAPAAAAAAAAAAAAAAACFvUUXQAlAQEBBgUSWnNj-fGgGUThYpiKwqM44eCGdgKgPw9ZzF11nXWu2gAA&vjk=f692d44d037a24fd'\n",
    "\n",
    "page3 = 'https://www.indeed.com/jobs?q=software+developer&l=Tempe%2C+AZ&radius=50&start=20&pp=gQAeAAAAAAAAAAAAAAACFvUUXQA_AQEBBwV46QPFC8nz2E2u-1MIy9Itv2eA7pn1hjdEqPtvIzLUAx1cRbeNYkfMLWSqsci8E9GqoOZiLpggVJKhAAA&vjk=132b5593778af710'\n",
    "\n",
    "page4 = 'https://www.indeed.com/jobs?q=software+developer&l=Tempe%2C+AZ&radius=50&start=30&pp=gQAtAAAAAAAAAAAAAAACFvUUXQBTAQEBBybSDRdyPu1SlltWZLhr3QfD9owJwFG0AZ6t2yaCmqtV28NBbIMOnYI5n8vpCzut8HfsOq8SS6Dgq8uRDwFXs7stlAzhiaMS0vigtkdOZ90AAA&vjk=3070b5f9430b22be'\n",
    "\n",
    "page5 = 'https://www.indeed.com/jobs?q=software+developer&l=Tempe%2C+AZ&radius=50&start=40&pp=gQA8AAAAAAAAAAAAAAACFvUUXQBrAQIBBxAHAWKcxt7ZrK1AjaS7uQDFnN382z5jElNrnSlNW0V0cwQB77MLxUEyZ8KollFv6Ai2uDiEVfO3hUzAxtA1VXxB5GFdZvJ5HJTiEOR_ypX9PZV4EE4Xr0zaIWFyL-Gx4iwttZnbg3wAAA&vjk=612e67caa3423240'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title = \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Function to extract Product Title\n",
    "def get_job_title(soup):\n",
    "\t\n",
    "\ttry:\n",
    "\t\t# Outer Tag Object\n",
    "\t\tjob_title = soup.find(\"span\", attrs={\"title\"})\n",
    "\n",
    "\t\t# Inner NavigableString Object\n",
    "\t\tjob_title_value = job_title.string\n",
    "\n",
    "\t\t# Title as a string value\n",
    "\t\tjob_title_string = job_title_value.strip()\n",
    "\n",
    "\t\t# # Printing types of values for efficient understanding\n",
    "\t\t# print(type(title))\n",
    "\t\t# print(type(title_value))\n",
    "\t\t# print(type(title_string))\n",
    "\t\t# print()\n",
    "\n",
    "\texcept AttributeError:\n",
    "\t\tjob_title_string = \"\"\t\n",
    "\n",
    "\treturn job_title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "\n",
    "\ttry:\n",
    "\t\tprice = soup.find(\"span\", attrs={'id':'priceblock_ourprice'}).string.strip()\n",
    "\n",
    "\texcept AttributeError:\n",
    "\t\tprice = \"\"\t\n",
    "\n",
    "\treturn price\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "\n",
    "\ttry:\n",
    "\t\trating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "\t\t\n",
    "\texcept AttributeError:\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\trating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "\t\texcept:\n",
    "\t\t\trating = \"\"\t\n",
    "\n",
    "\treturn rating\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "\ttry:\n",
    "\t\treview_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
    "\t\t\n",
    "\texcept AttributeError:\n",
    "\t\treview_count = \"\"\t\n",
    "\n",
    "\treturn review_count\n",
    "\n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "\ttry:\n",
    "\t\tavailable = soup.find(\"div\", attrs={'id':'availability'})\n",
    "\t\tavailable = available.find(\"span\").string.strip()\n",
    "\n",
    "\texcept AttributeError:\n",
    "\t\tavailable = \"\"\t\n",
    "\n",
    "\treturn available\t\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\t# Headers for request\n",
    "\tHEADERS = ({'User-Agent':\n",
    "\t            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "\t            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "\t# The webpage URL\n",
    "\tURL = \"https://www.indeed.com/jobs?q=software+developer&l=Tempe%2C+AZ&radius=50&start=40&pp=gQA8AAAAAAAAAAAAAAACFvUUXQBrAQIBBxAHAWKcxt7ZrK1AjaS7uQDFnN382z5jElNrnSlNW0V0cwQB77MLxUEyZ8KollFv6Ai2uDiEVfO3hUzAxtA1VXxB5GFdZvJ5HJTiEOR_ypX9PZV4EE4Xr0zaIWFyL-Gx4iwttZnbg3wAAA&vjk=612e67caa3423240\"\n",
    "\n",
    "\t# HTTP Request\n",
    "\twebpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "\t# Soup Object containing all data\n",
    "\tsoup = BeautifulSoup(webpage.content, \"lxml\")\n",
    "\n",
    "\t# Function calls to display all necessary product information\n",
    "\tprint(\"Job Title =\", get_job_title(soup))\n",
    "\t#print(\"Product Price =\", get_price(soup))\n",
    "\t#print(\"Product Rating =\", get_rating(soup))\n",
    "\t#print(\"Number of Product Reviews =\", get_review_count(soup))\n",
    "\t#print(\"Availability =\", get_availability(soup))\n",
    "\tprint()\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [403]>\n",
      "Failed to retrieve page. Status code: 403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_indeed_jobs(location, position):\n",
    "    base_url = f\"https://www.indeed.com/jobs?q=software+developer&l=Tempe%2C+AZ&radius=50&start=40&pp=gQA8AAAAAAAAAAAAAAACFvUUXQBrAQIBBxAHAWKcxt7ZrK1AjaS7uQDFnN382z5jElNrnSlNW0V0cwQB77MLxUEyZ8KollFv6Ai2uDiEVfO3hUzAxtA1VXxB5GFdZvJ5HJTiEOR_ypX9PZV4EE4Xr0zaIWFyL-Gx4iwttZnbg3wAAA&vjk=612e67caa3423240\"\n",
    "    response = requests.get(base_url)\n",
    "    print(response)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        job_listings = soup.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "        print(job_listings)\n",
    "        \n",
    "        for job in job_listings:\n",
    "            title = job.find('h2', class_='title').text.strip()\n",
    "            company = job.find('span', class_='company').text.strip()\n",
    "            location = job.find('span', class_='location').text.strip()\n",
    "            \n",
    "            print(f\"Title: {title}\\nCompany: {company}\\nLocation: {location}\\n---\\n\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "scrape_indeed_jobs(location='Tempe, AZ', position='Software Engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'yep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Harry\\Documents\\Web-Data-Scrappers-SWM\\CODE\\Beautiful-Soup\\INDEED.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m skill \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEnter your Skill: \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m place \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEnter the location: \u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m no_of_pages \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mEnter the # of pages to scrape: \u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m indeed_posts\u001b[39m=\u001b[39m[]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(no_of_pages):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m# Connecting to India Indeed\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'yep'"
     ]
    }
   ],
   "source": [
    "# this was used for the person contacting me who had these details for their system\n",
    "headers = {\n",
    "    \"User-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36\"}\n",
    "\n",
    "# Skills & Place of Work\n",
    "skill = input('Enter your Skill: ').strip()\n",
    "place = input('Enter the location: ').strip()\n",
    "no_of_pages = int(input('Enter the # of pages to scrape: '))\n",
    "\n",
    "indeed_posts=[]\n",
    "\n",
    "for page in range(no_of_pages):\n",
    "    \n",
    "    # Connecting to India Indeed\n",
    "        url = 'https://www.indeed.co.in/jobs?q=' + skill + \\\n",
    "            '&l=' + place + '&sort=date' +'&start='+ str(page * 10)\n",
    "        \n",
    "        # Get request to indeed with headers above (you don't need headers!)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        html = response.text\n",
    "        print(\"html=\", html)\n",
    "        # Scrapping the Web (you can use 'html' or 'lxml')\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        # Outer Most Entry Point of HTML:\n",
    "        outer_most_point=soup.find('div',attrs={'id': 'mosaic-provider-jobcards'})\n",
    "        \n",
    "        # \"UL\" lists where the data are stored:\n",
    "        \n",
    "        for i in outer_most_point.find('ul'):\n",
    "            \n",
    "        # Job Title:\n",
    "        \n",
    "            job_title=i.find('h2',{'class':'jobTitle jobTitle-color-purple jobTitle-newJob'})\n",
    "#             print(job_title)\n",
    "            if job_title != None:\n",
    "                jobs=job_title.find('a').text\n",
    "\n",
    "        # Company Name:\n",
    "    \n",
    "            if i.find('span',{'class':'companyName'}) != None:\n",
    "                company=i.find('span',{'class':'companyName'}).text   \n",
    "                \n",
    "        # Links: these Href links will take us to full job description\n",
    "        \n",
    "            if i.find('a') != None:\n",
    "                links=i.find('a',{'class':'jcs-JobTitle'})['href']\n",
    "                \n",
    "        # Salary if available:\n",
    "        \n",
    "            if i.find('div',{'class':'attribute_snippet'}) != None:\n",
    "                salary=i.find('div',{'class':'attribute_snippet'}).text\n",
    "\n",
    "            else:\n",
    "                salary='No Salary'\n",
    "\n",
    "        # Job Post Date:\n",
    "\n",
    "            if i.find('span', attrs={'class': 'date'}) != None:\n",
    "                post_date = i.find('span', attrs={'class': 'date'}).text\n",
    "\n",
    "        # Put everything together in a list of lists for the default dictionary\n",
    "                        \n",
    "            indeed_posts.append([company,jobs,links,salary, post_date])\n",
    "            \n",
    "            \n",
    "# put together in list\n",
    "\n",
    "# (create a dictionary with keys and a list of values from above \"indeed_posts\")\n",
    "\n",
    "indeed_dict_list=defaultdict(list)\n",
    "\n",
    "# Fields for our DF \n",
    "\n",
    "indeed_spec=['Company','job','link','Salary','Job_Posted_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resp =  <Response [403]> error code 403 forbidden error (indeed does not support crawling via beautiful soup it seems)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Harry\\Documents\\Web-Data-Scrappers-SWM\\CODE\\Beautiful-Soup\\INDEED.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W5sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m allData \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mul\u001b[39m\u001b[39m\"\u001b[39m,{\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mjobsearch-ResultsList css-0\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W5sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#print(\"alldata = \" , allData)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W5sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m alllitags \u001b[39m=\u001b[39m allData\u001b[39m.\u001b[39;49mfind_all(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m,{\u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mcardOutline\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W5sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(alllitags))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W5sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(alllitags)):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#from urllib.request import Request, urlopen\n",
    "\n",
    "\n",
    "\n",
    "l=[]\n",
    "o={}\n",
    "\n",
    "\n",
    "target_url = \"https://www.indeed.com/jobs?q=software+engineer&l=Tempe%2C+AZ&from=searchOnHP&vjk=00194e62da37d0c5\"\n",
    "head= {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Headers for request\n",
    "HEADERS = ({'User-Agent':\n",
    "\t            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "\t            'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "\t# The webpage URL\n",
    "URL = \"https://www.indeed.com/jobs?q=software+engineer&l=Tempe%2C+AZ&from=searchOnHP&vjk=00194e62da37d0c5\"\n",
    "\n",
    "# HTTP Request\n",
    "webpage = requests.get(URL, headers=HEADERS)\n",
    "print(\"resp = \", webpage, \"error code 403 forbidden error (indeed does not support crawling via beautiful soup it seems)\")\n",
    "\n",
    "\t# Soup Object containing all data\n",
    "soup = BeautifulSoup(webpage.content, \"lxml\")\n",
    "\n",
    "#resp = requests.get(target_url, headers=head)\n",
    "#print(\"resp = \", resp)\n",
    "#print(resp.status_code)\n",
    "#soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "allData = soup.find(\"ul\",{\"class\":\"jobsearch-ResultsList css-0\"})\n",
    "#print(\"alldata = \" , allData)\n",
    "\n",
    "alllitags = allData.find_all(\"div\",{\"class\":\"cardOutline\"})\n",
    "print(len(alllitags))\n",
    "for i in range(0,len(alllitags)):\n",
    "    try:\n",
    "        o[\"name-of-the-job\"]=alllitags[i].find(\"a\",{\"class\":\"jcs-JobTitle css-jspxzf eu4oa1w0\"}).text\n",
    "    except:\n",
    "        o[\"name-of-the-job\"]=None\n",
    "\n",
    "    try:\n",
    "        o[\"name-of-the-company\"]=alllitags[i].find(\"div\",{\"class\":\"companyInfo\"}).find(\"span\",{\"class\":\"companyName\"}).text\n",
    "    except:\n",
    "        o[\"name-of-the-company\"]=None\n",
    "\n",
    "\n",
    "    try:\n",
    "        o[\"rating\"]=alllitags[i].find(\"div\",{\"class\":\"companyInfo\"}).find(\"span\",{\"class\":\"ratingsDisplay\"}).text\n",
    "    except:\n",
    "        o[\"rating\"]=None\n",
    "\n",
    "    try:\n",
    "        o[\"salary\"]=alllitags[i].find(\"div\",{\"class\":\"salary-snippet-container\"}).text\n",
    "    except:\n",
    "        o[\"salary\"]=None\n",
    "\n",
    "    try:\n",
    "        o[\"job-details\"]=alllitags[i].find(\"div\",{\"class\":\"metadata taxoAttributes-container\"}).find(\"ul\").text\n",
    "    except:\n",
    "        o[\"job-details\"]=None\n",
    "\n",
    "    l.append(o)\n",
    "    o={}\n",
    "\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'capabilities'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:38\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[1;34m(service, options)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     path \u001b[39m=\u001b[39m SeleniumManager()\u001b[39m.\u001b[39;49mdriver_location(options) \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\selenium_manager.py:75\u001b[0m, in \u001b[0;36mSeleniumManager.driver_location\u001b[1;34m(self, options)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[39m\"\"\"Determines the path of the correct driver.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[39m:Args:\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m - browser: which browser to get the driver path for.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m:Returns: The driver path to use\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m browser \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39;49mcapabilities[\u001b[39m\"\u001b[39m\u001b[39mbrowserName\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     77\u001b[0m args \u001b[39m=\u001b[39m [\u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_binary()), \u001b[39m\"\u001b[39m\u001b[39m--browser\u001b[39m\u001b[39m\"\u001b[39m, browser]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Harry\\Documents\\Web-Data-Scrappers-SWM\\CODE\\Beautiful-Soup\\INDEED.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m paginaton_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://www.indeed.com/jobs?q=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m&l=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m&radius=35&start=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# initialize Chrome webdriver using ChromeDriverManager\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m driver \u001b[39m=\u001b[39m webdriver\u001b[39m.\u001b[39;49mChrome(ChromeDriverManager()\u001b[39m.\u001b[39;49minstall())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# open initial URL\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m driver\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mhttps://www.indeed.com/q-USA-jobs.html?vjk=823cd7ee3c203ac3\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[39m=\u001b[39m service \u001b[39mif\u001b[39;00m service \u001b[39melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[39m=\u001b[39m options \u001b[39mif\u001b[39;00m options \u001b[39melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     46\u001b[0m     DesiredCapabilities\u001b[39m.\u001b[39;49mCHROME[\u001b[39m\"\u001b[39;49m\u001b[39mbrowserName\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     47\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mgoog\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     48\u001b[0m     options,\n\u001b[0;32m     49\u001b[0m     service,\n\u001b[0;32m     50\u001b[0m     keep_alive,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:51\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvendor_prefix \u001b[39m=\u001b[39m vendor_prefix\n\u001b[0;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice \u001b[39m=\u001b[39m service\n\u001b[1;32m---> 51\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mpath \u001b[39m=\u001b[39m DriverFinder\u001b[39m.\u001b[39;49mget_path(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mservice, options)\n\u001b[0;32m     53\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mservice\u001b[39m.\u001b[39mstart()\n\u001b[0;32m     55\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\selenium\\webdriver\\common\\driver_finder.py:40\u001b[0m, in \u001b[0;36mDriverFinder.get_path\u001b[1;34m(service, options)\u001b[0m\n\u001b[0;32m     38\u001b[0m     path \u001b[39m=\u001b[39m SeleniumManager()\u001b[39m.\u001b[39mdriver_location(options) \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m---> 40\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnable to obtain driver for \u001b[39m\u001b[39m{\u001b[39;00moptions\u001b[39m.\u001b[39mcapabilities[\u001b[39m'\u001b[39m\u001b[39mbrowserName\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m using Selenium Manager.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m     \u001b[39mraise\u001b[39;00m NoSuchDriverException(msg) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m Path(path)\u001b[39m.\u001b[39mis_file():\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'capabilities'"
     ]
    }
   ],
   "source": [
    "# import necessary modules\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree as et\n",
    "from csv import writer\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# define job and location search keywords\n",
    "job_search_keyword = [' Data+Scientist', 'Business+Analyst', 'Data+Engineer', 'Python+Developer', 'Full+Stack+Developer', 'Machine+Learning+Engineer']\n",
    "location_search_keyword = ['New+York', 'California', 'Los+Angeles']\n",
    "\n",
    "# define base and pagination URLs\n",
    "base_url = 'https://www.indeed.com'\n",
    "paginaton_url = \"https://www.indeed.com/jobs?q={}&l={}&radius=35&start={}\"\n",
    "\n",
    "\n",
    "# initialize Chrome webdriver using ChromeDriverManager\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "# open initial URL\n",
    "driver.get(\"https://www.indeed.com/q-USA-jobs.html?vjk=823cd7ee3c203ac3\")\n",
    "\n",
    "\n",
    "\n",
    "# function to get DOM from given URL\n",
    "def get_dom(url):\n",
    "   driver.get(url)\n",
    "   page_content = driver.page_source\n",
    "   product_soup = BeautifulSoup(page_content, 'html.parser')\n",
    "   dom = et.HTML(str(product_soup))\n",
    "   return dom\n",
    "\n",
    "\n",
    "\n",
    "# functions to extract job link\n",
    "def get_job_link(job):\n",
    "   try:\n",
    "       job_link = job.xpath('./descendant::h2/a/@href')[0]\n",
    "   except Exception as e:\n",
    "       job_link = 'Not available'\n",
    "   return job_link\n",
    "\n",
    "\n",
    "# functions to extract job title\n",
    "def get_job_title(job):\n",
    "   try:\n",
    "       job_title = job.xpath('./descendant::h2/a/span/text()')[0]\n",
    "   except Exception as e:\n",
    "       job_title = 'Not available'\n",
    "   return job_title\n",
    "\n",
    "\n",
    "# functions to extract the company name\n",
    "def get_company_name(job):\n",
    "   try:\n",
    "       company_name = job.xpath('./descendant::span[@class=\"companyName\"]/text()')[0]\n",
    "   except Exception as e:\n",
    "       company_name = 'Not available'\n",
    "   return company_name\n",
    "\n",
    "\n",
    "# functions to extract the company location\n",
    "def get_company_location(job):\n",
    "   try:\n",
    "       company_location = job.xpath('./descendant::div[@class=\"companyLocation\"]/text()')[0]\n",
    "   except Exception as e:\n",
    "       company_location = 'Not available'\n",
    "   return company_location\n",
    "\n",
    "\n",
    "# functions to extract salary information\n",
    "def get_salary(job):\n",
    "   try:\n",
    "       salary = job.xpath('./descendant::span[@class=\"estimated-salary\"]/span/text()')\n",
    "   except Exception as e:\n",
    "       salary = 'Not available'\n",
    "   if len(salary) == 0:\n",
    "       try:\n",
    "           salary = job.xpath('./descendant::div[@class=\"metadata salary-snippet-container\"]/div/text()')[0]\n",
    "       except Exception as e:\n",
    "           salary = 'Not available'\n",
    "   else:\n",
    "       salary = salary[0]\n",
    "   return salary\n",
    "\n",
    "\n",
    "# functions to extract job type\n",
    "def get_job_type(job):\n",
    "   try:\n",
    "       job_type = job.xpath('./descendant::div[@class=\"metadata\"]/div/text()')[0]\n",
    "   except Exception as e:\n",
    "       job_type = 'Not available'\n",
    "   return job_type\n",
    "\n",
    "\n",
    "# functions to extract job rating\n",
    "def get_rating(job):\n",
    "   try:\n",
    "       rating = job.xpath('./descendant::span[@class=\"ratingNumber\"]/span/text()')[0]\n",
    "   except Exception as e:\n",
    "       rating = 'Not available'\n",
    "   return rating\n",
    "\n",
    "\n",
    "# functions to extract job description\n",
    "def get_job_desc(job):\n",
    "   try:\n",
    "       job_desc = job.xpath('./descendant::div[@class=\"job-snippet\"]/ul/li/text()')\n",
    "   except Exception as e:\n",
    "       job_desc = ['Not available']\n",
    "   if job_desc:\n",
    "       job_desc = \",\".join(job_desc)\n",
    "   else:\n",
    "       job_desc = 'Not available'\n",
    "   return job_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Harry\\Documents\\Web-Data-Scrappers-SWM\\CODE\\Beautiful-Soup\\INDEED.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#X20sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         outer_most_point\u001b[39m=\u001b[39msoup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m,attrs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmosaic-provider-jobcards\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#X20sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39m# \"UL\" lists where the data are stored:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m outer_most_point\u001b[39m.\u001b[39;49mfind(\u001b[39m'\u001b[39m\u001b[39mul\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m             \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#X20sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39m# Job Title:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#X20sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m             job_title\u001b[39m=\u001b[39mi\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mh2\u001b[39m\u001b[39m'\u001b[39m,{\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mjobTitle jobTitle-color-purple jobTitle-newJob\u001b[39m\u001b[39m'\u001b[39m})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Harry/Documents/Web-Data-Scrappers-SWM/CODE/Beautiful-Soup/INDEED.ipynb#X20sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m#             print(job_title)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "# this was used for the person contacting me who had these details for their system\n",
    "headers = {\n",
    "    \"User-agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36\"}\n",
    "\n",
    "# Skills & Place of Work\n",
    "skill = input('Enter your Skill: ').strip()\n",
    "place = input('Enter the location: ').strip()\n",
    "no_of_pages = int(input('Enter the # of pages to scrape: '))\n",
    "\n",
    "indeed_posts=[]\n",
    "\n",
    "for page in range(no_of_pages):\n",
    "    \n",
    "    # Connecting to India Indeed\n",
    "        url = 'https://www.indeed.co.in/jobs?q=' + skill + \\\n",
    "            '&l=' + place + '&sort=date' +'&start='+ str(page * 10)\n",
    "        \n",
    "        # Get request to indeed with headers above (you don't need headers!)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        html = response.text\n",
    "\n",
    "        # Scrapping the Web (you can use 'html' or 'lxml')\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        # Outer Most Entry Point of HTML:\n",
    "        outer_most_point=soup.find('div',attrs={'id': 'mosaic-provider-jobcards'})\n",
    "        \n",
    "        # \"UL\" lists where the data are stored:\n",
    "        \n",
    "        for i in outer_most_point.find('ul'):\n",
    "            \n",
    "        # Job Title:\n",
    "        \n",
    "            job_title=i.find('h2',{'class':'jobTitle jobTitle-color-purple jobTitle-newJob'})\n",
    "#             print(job_title)\n",
    "            if job_title != None:\n",
    "                jobs=job_title.find('a').text\n",
    "\n",
    "        # Company Name:\n",
    "    \n",
    "            if i.find('span',{'class':'companyName'}) != None:\n",
    "                company=i.find('span',{'class':'companyName'}).text   \n",
    "                \n",
    "        # Links: these Href links will take us to full job description\n",
    "        \n",
    "            if i.find('a') != None:\n",
    "                links=i.find('a',{'class':'jcs-JobTitle'})['href']\n",
    "                \n",
    "        # Salary if available:\n",
    "        \n",
    "            if i.find('div',{'class':'attribute_snippet'}) != None:\n",
    "                salary=i.find('div',{'class':'attribute_snippet'}).text\n",
    "\n",
    "            else:\n",
    "                salary='No Salary'\n",
    "\n",
    "        # Job Post Date:\n",
    "\n",
    "            if i.find('span', attrs={'class': 'date'}) != None:\n",
    "                post_date = i.find('span', attrs={'class': 'date'}).text\n",
    "\n",
    "        # Put everything together in a list of lists for the default dictionary\n",
    "                        \n",
    "            indeed_posts.append([company,jobs,links,salary, post_date])\n",
    "            \n",
    "            \n",
    "# put together in list\n",
    "\n",
    "# (create a dictionary with keys and a list of values from above \"indeed_posts\")\n",
    "\n",
    "indeed_dict_list=defaultdict(list)\n",
    "\n",
    "# Fields for our DF \n",
    "\n",
    "indeed_spec=['Company','job','link','Salary','Job_Posted_Date']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
